{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ead94eb2",
   "metadata": {},
   "source": [
    "# Ausführen des Netzwerks\n",
    "\n",
    "\n",
    "Mit Hilfe dieses Notebooks können Sie ihr zuvor trainiertes und qunatisiertes Netzwerk ausführen.\n",
    "Hier gibt es keine explizite Aufgabe der Sie nachgehen sollen.\n",
    "\n",
    "* Drucken Sie sich ein paar Mnist-Zahlen aus oder schreiben Sie einige Zahlen auf ein Blatt.\n",
    "* Klassifizieren Sie diese Zahlen. Sie werden feststellen, dass die korrekte Klassifizierung abhängig von der Position der Zahl ist.\n",
    "\n",
    "\n",
    "### Auf eigene Faust\n",
    "\n",
    "Denken Sie sich eigene Aufgaben aus:\n",
    "\n",
    "\n",
    "Sie können Beispielsweise versuchen das Netzwerk so zu trainieren, dass die Position der Zahl nicht zentriert sein muss (Stichwort data augmentation).\n",
    "\n",
    "\n",
    "Seien Sie kreativ und spielen Sie ein bisschen herum, vielleicht kommt ihnen eine eigene Aufgabe in den Sinn.\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75f93159",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pycoral.adapters'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[1;32mIn [3]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpycoral\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01madapters\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m classify\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpycoral\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01madapters\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m common\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpycoral\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01medgetpu\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m make_interpreter, list_edge_tpus\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'pycoral.adapters'"
     ]
    }
   ],
   "source": [
    "from pycoral.adapters import classify\n",
    "from pycoral.adapters import common\n",
    "from pycoral.utils.edgetpu import make_interpreter, list_edge_tpus\n",
    "import pycoral\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import ImageDraw \n",
    "from PIL import ImageFont\n",
    "from PIL import ImageDraw\n",
    "from PIL import Image\n",
    "import traceback\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf279b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to replace this string with the name of your model\n",
    "MODEL = \"./cnn_quant_edgetpu.tflite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c88dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load our model\n",
    "interpreter = make_interpreter(MODEL)\n",
    "\n",
    "# move it to the TPU\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get our input-details directly from our Model, so we don't need to hardcode the shape\n",
    "input_details = interpreter.get_input_details()\n",
    "input_shape = input_details[0]['shape']\n",
    "\n",
    "# Not really useful at this point.. maybe use a print statement to inspect it?\n",
    "output_details = interpreter.get_output_details()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0a1bed",
   "metadata": {},
   "outputs": [],
   "source": [
    " def show_image(a, fmt='jpeg'):\n",
    "    ##\n",
    "    # Display Image-stream in ipython\n",
    "    # Does not work smoothly in firefox\n",
    "    #\n",
    "    \n",
    "    import numpy as np\n",
    "    from IPython.display import clear_output, Image, display\n",
    "    from io import StringIO, BytesIO\n",
    "    import PIL.Image\n",
    "    \n",
    "    faux_file = BytesIO()\n",
    "    \n",
    "    a = np.uint8(np.clip(a, 0, 255))\n",
    "    PIL.Image.fromarray(a).save(faux_file, fmt)\n",
    "    clear_output(wait=True)\n",
    "    imgdata = Image(data=faux_file.getvalue())\n",
    "    display(imgdata)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d3fc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def preprocessing(img):\n",
    "    \n",
    "    # We need have to resize to 28x28 pixel\n",
    "        \n",
    "    to_classify = cv2.resize(img, (28,28) , interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    # Trainingsdata is white on black so we inverse it\n",
    "    to_classify = cv2.bitwise_not(to_classify)\n",
    "    \n",
    "    # set all pixel below a threshold to zero so we remove some noise\n",
    "    to_classify[np.where(to_classify < 150)] = 0\n",
    "    return to_classify\n",
    "\n",
    "def predict(img):\n",
    "    \n",
    "    # We resized the image in our prepocessing-step, but the input-shape can be different\n",
    "    img = img.reshape((*input_shape))\n",
    "    \n",
    "    # feed our interpreter with data\n",
    "    interpreter.set_tensor(input_details[0]['index'], img)\n",
    "    \n",
    "    # run it\n",
    "    interpreter.invoke()\n",
    "    \n",
    "    # get output\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    \n",
    "    # make output a distribution\n",
    "    return output_data/output_data.sum()\n",
    "\n",
    "\n",
    "def score2img(img,pred,threshold = 0.7):\n",
    "    \n",
    "    \"\"\"\n",
    "        Just a routine to add some text to a image\n",
    "    \"\"\"\n",
    "    scoreboard = 250\n",
    "    font = ImageFont.truetype(\"Noto Mono Nerd Font Complete.ttf\", size=24)\n",
    "    z = np.zeros_like(img)\n",
    "    img = np.concatenate((z[:,:scoreboard+3],img),axis=1)\n",
    "    img = np.dstack([img]*3)\n",
    "    img[:,scoreboard:scoreboard+2] = [255,255,255]\n",
    "    label = \"\"\n",
    "    score = \"\"\n",
    "    if pred.max() >= threshold:\n",
    "        label = \"label    : {}\".format(pred.argmax())\n",
    "        score = \"score    : {:.3f}\".format(pred.max())\n",
    "        \n",
    "    pred = list(pred[0])\n",
    "    score_list = [ (i,pred[i]) for i in range(len(pred))]\n",
    "    sorted_score_list = sorted(score_list, key=lambda tup: tup[1],reverse=True)\n",
    "    \n",
    "    \n",
    "    img = Image.fromarray(img)    \n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    draw.text((15,0),\"Threshold: {}\".format(threshold),(255,255,255),font = font)\n",
    "    draw.text((15,25),label,(255,255,255),font = font)\n",
    "    draw.text((15,50),score,(255,255,255),font = font)\n",
    "    \n",
    "    draw.text((15,75),\"class | score\",(255,255,255),font = font)\n",
    "    for i,(l,s) in enumerate(sorted_score_list):\n",
    "        \n",
    "        if i==0:\n",
    "            color = (0,255,0)\n",
    "        else:\n",
    "            color = (255,255,255)\n",
    "        txt = \"{:<6}| {:.3f}\".format(l,s)\n",
    "        draw.text((15,100+(25*i)),txt,color,font = font)\n",
    "        \n",
    "        \n",
    "    return np.array(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9555bacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "cap = cv2.VideoCapture(1)\n",
    "try:\n",
    "    while(True):\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            \n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            to_classify = preprocessing(gray)\n",
    "            \n",
    "            prediction = predict(to_classify)\n",
    "            to_classify = cv2.resize(to_classify, (gray.shape[1],gray.shape[0]) , interpolation = cv2.INTER_AREA)\n",
    "            \n",
    "            \n",
    "            img2show = np.concatenate((to_classify,gray),axis=1)\n",
    "            x,y = frame.shape[:2]\n",
    "\n",
    "            \n",
    "            # This rectangle is for orientation purpose only\n",
    "            \n",
    "            leftpt = -180\n",
    "            rightpt = 180\n",
    "            rectangle = ([leftpt+255+y//2,leftpt+x//2],(rightpt+255+y//2,rightpt+x//2))\n",
    "            img2show = score2img(img2show,prediction)\n",
    "            img2show = cv2.rectangle(img2show,tuple(rectangle[0]),tuple(rectangle[1]),(255,0,0),3)\n",
    "\n",
    "            show_image(img2show)\n",
    "\n",
    "\n",
    "except ValueError as e:\n",
    "    traceback.print_exc()\n",
    "except AttributeError as e:\n",
    "    traceback.print_exc()\n",
    "except TypeError as e:\n",
    "    traceback.print_exc()\n",
    "except OSError as e:\n",
    "    traceback.print_exc()\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "# When everything done, release the capture\n",
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}